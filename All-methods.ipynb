{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROggr91DhbSP"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm==4.67.1 | tail -n 1\n",
        "!pip install numpy==2.2.0 | tail -n 1\n",
        "!pip install pandas==2.2.3 | tail -n 1\n",
        "!pip install matplotlib==3.9.4 | tail -n 1\n",
        "!pip install seaborn==0.13.2 | tail -n 1\n",
        "!pip install scikit-learn==1.6.0 | tail -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0zOnPZHhbSQ"
      },
      "source": [
        "### <a id='importing-required-libraries'></a>[Importing required libraries](#toc)\n",
        "\n",
        "We recommend you import all required libraries in one place (here):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEYPVCRzhbSQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import export_text, plot_tree\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# You can also use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_context('notebook')\n",
        "sns.set_style('white')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMUTfOLwhbSR"
      },
      "source": [
        "### <a id='defining-helper-functions'></a>[Defining helper functions](#toc)\n",
        "\n",
        "The following function `display_feature_importance` visualizes and ranks the importance of features for a trained **Decision Tree** or **Random Forest** model.\n",
        "\n",
        "It calculates feature importances, organizes them into a sorted DataFrame, and generates a horizontal bar plot to highlight the relative importance of each feature.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJfxLJ6YhbSR"
      },
      "outputs": [],
      "source": [
        "def display_feature_importances(model, feature_names):\n",
        "    \"\"\"\n",
        "    Displays feature importances for a Decision Tree or Random Forest model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: A trained DecisionTreeClassifier or RandomForestClassifier from sklearn.\n",
        "    - feature_names: List of feature names corresponding to the columns in X_train.\n",
        "\n",
        "    Returns:\n",
        "    - A DataFrame sorted by feature importance.\n",
        "    \"\"\"\n",
        "    # Get feature importances from the model\n",
        "    feature_importance = model.feature_importances_\n",
        "\n",
        "    # Create a DataFrame to display feature names and their importance\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': feature_importance\n",
        "    })\n",
        "\n",
        "    # Sort by importance (highest to lowest)\n",
        "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Plot the feature importance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
        "    plt.xlabel('Importance')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.title('Feature Importance')\n",
        "    plt.gca().invert_yaxis()  # To show the highest importance on top\n",
        "    plt.show()\n",
        "\n",
        "    # Return the sorted DataFrame\n",
        "    return feature_importance_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOV_Pe_hhbSR"
      },
      "source": [
        "The following helper class `TreeSplanerClassifier`, provides tools to interpret and extract decision rules from a trained Decision Tree model and present them in human-readable natural language. It includes methods for identifying paths through the tree, converting the structure into text-based rules, and analyzing predictions and impurity. A breakdown of its functionality follows:\n",
        "\n",
        "#### Functions:\n",
        "\n",
        "1. **`__init__`**:\n",
        "   - Initializes the class with a trained decision tree model.\n",
        "   - Extracts and caches tree attributes such as node thresholds, feature indices, and child nodes.\n",
        "   - Allows optional input of feature and target names for readability.\n",
        "\n",
        "2. **`find_paths_from_root`**:\n",
        "   - Recursively identifies all paths from the root node to the leaf nodes.\n",
        "   - Outputs a list of paths, where each path is represented by a sequence of node indices.\n",
        "\n",
        "3. **`decision_tree_to_text`**:\n",
        "   - Converts the tree's decision structure into natural language rules.\n",
        "   - For each path, it generates a rule in the format:\n",
        "     - \"If feature1 <= threshold1 and feature2 > threshold2, then the class is X with probability Y.\"\n",
        "\n",
        "4. **`build_text_prediction`**:\n",
        "   - Provides natural language predictions for specific input samples.\n",
        "   - Describes the path taken through the tree and explains the prediction and probability.\n",
        "\n",
        "5. **`branch_impurity`**:\n",
        "   - Computes and returns the impurity at each split along all paths from the root to the leaves.\n",
        "   - Provides insights into how pure or mixed the splits are along the decision paths.\n",
        "\n",
        "#### Use case:\n",
        "\n",
        "This class is ideal for generating explainable AI outputs from Decision Trees, enabling users to understand model decisions in terms of easily interpretable rules and probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9DVZoyphbSR"
      },
      "outputs": [],
      "source": [
        "class TreeSplanerClassifier:\n",
        "    \"\"\"\n",
        "    A class to extract and convert decision rules from a trained decision tree into natural language.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, clf, feature_names=None, target_names=None):\n",
        "        self.clf = clf\n",
        "        # Explicitly check if feature_names or target_names are None\n",
        "        if feature_names is None:\n",
        "            self.feature_names = [f\"feature_{i}\" for i in range(clf.tree_.n_features)]\n",
        "        else:\n",
        "            self.feature_names = feature_names\n",
        "\n",
        "        if target_names is None:\n",
        "            self.target_names = [f\"class_{i}\" for i in range(clf.tree_.n_classes)]\n",
        "        else:\n",
        "            self.target_names = target_names\n",
        "\n",
        "        # Cache commonly used tree attributes\n",
        "        self.children_left = clf.tree_.children_left\n",
        "        self.children_right = clf.tree_.children_right\n",
        "        self.feature = clf.tree_.feature\n",
        "        self.threshold = clf.tree_.threshold\n",
        "        self.value = clf.tree_.value\n",
        "\n",
        "    def find_paths_from_root(self, node=0, path=None, all_paths=None):\n",
        "        \"\"\"Recursively finds all paths from the root node to each leaf node.\"\"\"\n",
        "        if path is None:\n",
        "            path = []\n",
        "        if all_paths is None:\n",
        "            all_paths = []\n",
        "\n",
        "        path.append(node)\n",
        "\n",
        "        # Check if it is a leaf node\n",
        "        if self.children_left[node] == -1 and self.children_right[node] == -1:\n",
        "            all_paths.append(list(path))\n",
        "        else:\n",
        "            # Recursively explore the left and right children\n",
        "            if self.children_left[node] != -1:\n",
        "                self.find_paths_from_root(self.children_left[node], path, all_paths)\n",
        "            if self.children_right[node] != -1:\n",
        "                self.find_paths_from_root(self.children_right[node], path, all_paths)\n",
        "\n",
        "        path.pop()\n",
        "\n",
        "        return all_paths\n",
        "\n",
        "    def decision_tree_to_text(self):\n",
        "        \"\"\"\n",
        "        Converts the tree's structure into a natural language description of its decision rules.\n",
        "        \"\"\"\n",
        "        all_paths = self.find_paths_from_root()\n",
        "        branch = \"If \"\n",
        "        number_paths = len(all_paths)\n",
        "\n",
        "\n",
        "        for p, path in enumerate(all_paths):\n",
        "            branch += \" (\"\n",
        "            for l, node in enumerate(path):\n",
        "\n",
        "\n",
        "\n",
        "                # Determine inequality direction based on child position\n",
        "                if node in self.children_right:\n",
        "                    eq = \">\"\n",
        "\n",
        "\n",
        "                elif node==0 and  path[l+1] in  self.children_right:\n",
        "                    eq = \">\"\n",
        "\n",
        "                else:\n",
        "                    eq = \"<=\"\n",
        "\n",
        "                if l != len(path) - 1:\n",
        "                    branch += f\"{self.feature_names[self.feature[node]]} {eq} {round(self.threshold[node], 2)} and \"\n",
        "                else:\n",
        "                    target_index=np.argmax(self.value[node, 0, :])\n",
        "\n",
        "                    predicted_class = self.target_names[target_index]\n",
        "                    probability_class=round(self.clf.tree_.value[node,0,target_index],3)\n",
        "                    branch += f\"{self.feature_names[self.feature[node]]} {eq} {round(self.threshold[node], 2)} then class is {predicted_class}  with probability of {probability_class}\"\n",
        "            branch += \" )\" + (\" or\" if p != number_paths - 1 else \"\")\n",
        "        return branch\n",
        "\n",
        "\n",
        "    def build_text_prediction(self, samples):\n",
        "        \"\"\"\n",
        "        Generates natural language predictions for specific samples.\n",
        "        \"\"\"\n",
        "        branches = []\n",
        "\n",
        "        for sample in samples:\n",
        "            sample = np.array(sample).reshape(1, -1)\n",
        "            node_indicator = self.clf.decision_path(sample)\n",
        "            predicted_index=int(self.clf.predict(sample)[0])\n",
        "            predicted_class = self.target_names[predicted_index]\n",
        "\n",
        "            probability_class=np.round(self.clf.predict_proba(sample)[0][predicted_index],3)\n",
        "\n",
        "            branch = \"\"\n",
        "\n",
        "            # Get the path for the current sample\n",
        "            path = node_indicator.indices\n",
        "            for n, node in enumerate(path):\n",
        "                # Determine inequality direction based on child position\n",
        "                if node in self.children_right:\n",
        "                    eq = \">\"\n",
        "                else:\n",
        "                    eq = \"<=\"\n",
        "\n",
        "                if n != len(path) - 1:\n",
        "                    branch += f\"{self.feature_names[self.feature[node]]} {eq} {round(self.threshold[node], 2)} and \"\n",
        "                else:\n",
        "                    branch += f\"{self.feature_names[self.feature[node]]} {eq} {round(self.threshold[node], 2)} therefore the class is {predicted_class} with probability of {probability_class}\"\n",
        "\n",
        "            branches.append(branch)\n",
        "\n",
        "        return branches\n",
        "\n",
        "    def branch_impurity(self):\n",
        "        all_paths=self.find_paths_from_root()\n",
        "        node_impurity=self.clf.tree_.impurity\n",
        "        feature=self.feature\n",
        "        branch_impurity=\"\"\n",
        "        for p, path in enumerate(all_paths):\n",
        "            branch_impurity+=f\" For branch {p+1} \"\n",
        "\n",
        "            for node in path:\n",
        "\n",
        "                branch_impurity+=f\" for split  {node } and feature {self.feature_names[feature[node]]} impurity is {round(node_impurity[node],3)} \"\n",
        "        return branch_impurity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQKEtvkhbSR"
      },
      "source": [
        "### <a id='data-preprocessing'></a>[Data preprocessing](#toc)\n",
        "\n",
        "Let's begin with loading the dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPE52juwhbSR"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/6exL12iQvqfWQgXniFXM4g/Predict%20Student%20Dropout%20and%20Academic%20Success.csv\", delimiter=\";\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psx1r8_yhbSR"
      },
      "source": [
        "### <a id='dataset-description'></a>[Dataset description](#toc)\n",
        "\n",
        "Here is the link to the dataset: [Predict Students' Dropout and Academic Success dataset](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success)\n",
        "\n",
        "| **Column Name**                              | **Categories / Values**                                                                                  | **Description**                                          |\n",
        "|---------------------------------------------|----------------------------------------------------------------------------------------------------------|--------------------------------------------------------|\n",
        "| **Marital status**                          | 1 - Single, 2 - Married, 3 - Widower, 4 - Divorced, 5 - Facto Union, 6 - Legally Separated               | The marital status of the student                     |\n",
        "| **Application mode**                        | Various numerical codes (e.g., 1, 2, 5, 7, 10, 15, 17, etc.)                                             | Type or mode of application for enrollment            |\n",
        "| **Application order**                       | 0 - First choice, 1-9 - Subsequent choices                                                              | Order of preference when applying for the course      |\n",
        "| **Course**                                  | Numerical codes representing specific courses (e.g., 33, 171, 8014, 9003, 9500, etc.)                    | The course or degree program the student enrolled in  |\n",
        "| **Daytime/evening attendance**              | 1 - Daytime, 0 - Evening                                                                                 | Specifies if the student attends during day/evening   |\n",
        "| **Previous qualification**                  | 1 - Secondary education, 2 - Higher education (Bachelor's), 3 - Degree, 4 - Master's, 5 - Doctorate, etc.| Type of previous academic qualification               |\n",
        "| **Previous qualification (grade)**          | 0 to 200                                                                                                | Final grade/score in previous academic qualification  |\n",
        "| **Nationality**                             | 1 - Portuguese, 2 - German, 6 - Spanish, 41 - Brazilian, etc.                                            | Nationality of the student                            |\n",
        "| **Mother's qualification**                  | 1 - Secondary education, 2 - Bachelor's, 3 - Degree, 4 - Master's, 5 - Doctorate, etc.                  | Mother's highest academic qualification               |\n",
        "| **Father's qualification**                  | 1 - Secondary education, 2 - Bachelor's, 3 - Degree, 4 - Master's, 5 - Doctorate, etc.                  | Father's highest academic qualification               |\n",
        "| **Curricular units 1st sem (grade)**         | 0 to 20                                                                                                 | Average grade in the 1st semester                     |\n",
        "| **Curricular units 1st sem (without evaluations)** | Integer values (e.g., 0, 1, 2, etc.)                                                                     | Number of units without evaluations in the 1st sem    |\n",
        "| **Curricular units 2nd sem (credited)**      | Integer values (e.g., 0, 1, 2, etc.)                                                                     | Number of credited units in the 2nd semester          |\n",
        "| **Curricular units 2nd sem (enrolled)**      | Integer values (e.g., 0, 1, 2, etc.)                                                                     | Number of units enrolled in the 2nd semester          |\n",
        "| **Curricular units 2nd sem (evaluations)**   | Integer values (e.g., 0, 1, 2, etc.)                                                                     | Number of evaluations in the 2nd semester             |\n",
        "| **Curricular units 2nd sem (approved)**      | Integer values (e.g., 0, 1, 2, etc.)                                                                     | Number of units approved in the 2nd semester          |\n",
        "| **Curricular units 2nd sem (grade)**         | 0 to 20                                                                                                 | Average grade in the 2nd semester                     |\n",
        "| **Curricular units 2nd sem (without evaluations)** | Integer values (e.g., 0, 1, 2, etc.)                                                                     | Units without evaluations in the 2nd semester         |\n",
        "| **Unemployment rate**                       | Continuous percentage values (e.g., 5.0%, 10.0%)                                                         | Unemployment rate                                     |\n",
        "| **Inflation rate**                          | Continuous percentage values (e.g., 1.5%, 2.5%)                                                          | Inflation rate                                        |\n",
        "| **GDP**                                     | Continuous numerical values (e.g., GDP in millions or billions)                                           | Gross Domestic Product                                |\n",
        "| **Target**                                  | Dropout, Enrolled, Graduate                                                                              | The final academic outcome of the student             |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhHMrBi6hbSS"
      },
      "source": [
        "Print the shape of the dataset to understand the number of rows and columns and  column names for a quick overview of the features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJyiETIahbSS"
      },
      "outputs": [],
      "source": [
        "print(\"\\nShape of the dataset (rows, columns):\", df.shape)\n",
        "\n",
        "print(\"\\nColumns in the dataset:\", df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSZDUfelhbSS"
      },
      "source": [
        "Display the count of unique values in the 'Target' column to understand class distribution. The `Target` column has 2209 `Graduate`, 1421 `Dropout`, and 794 `Enrolled` cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWnsj7LzhbSS"
      },
      "outputs": [],
      "source": [
        "df['Target'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyILkEaThbSS"
      },
      "source": [
        "Visualize the distribution of the target variable:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVclwOpOhbSS"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='Target', data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPAZzwiIhbSS"
      },
      "source": [
        " Display summary statistics for numerical columns:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5rSA0N-hbSS"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbdZc8rihbST"
      },
      "source": [
        "From the dataset description, it is clear that several features, such as **`Marital Status`**, **`Nationality`**, **`Course`**, and others, are **categorical** but represented as numerical values. These numbers act as **labels** or **codes** for different categories and do not carry any ordinal or numerical meaning.\n",
        "\n",
        "For example:\n",
        "- The mean of **`Marital Status`** in the dataset is **1.17**, which is illogical because averaging categories such as *Single*, *Married*, and *Widower* does not make sense.\n",
        "\n",
        "#### Why this matters:\n",
        "Treating such features as **numerical** can lead to incorrect or misleading results in analysis and modeling:\n",
        "1. Calculating statistics such as the **mean** or **standard deviation** on categorical features does not provide any meaningful insights.\n",
        "2. Using these features directly in machine learning models may introduce unintended biases or errors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot1PuNKxhbST"
      },
      "source": [
        "To check how many categories are there in a feature, use:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45rZEnd1hbST"
      },
      "outputs": [],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU8gwhNmhbST"
      },
      "source": [
        "### <a id='feature-engineering'></a>[Feature engineering](#toc)\n",
        "\n",
        "#### Mapping dataset\n",
        "\n",
        "From the dataset, we can see that there are many categories in a various features. Now, to make the process simpler, we have mapped the values of categories to new values (grouped them together) to reduce the number of columns to work with. A snippet of one of the features that was mapped (`Marital status`), follows:\n",
        "\n",
        "```\n",
        "# Function to map categories to numbers\n",
        "def map_categories(row, feature, mapping):\n",
        "    return mapping.get(row[feature], -1)  # Default to -1 if the value is not in the mapping\n",
        "\n",
        "\n",
        "# Reduce Marital Status categories\n",
        "marital_status_mapping = {\n",
        "    1: 1,  # Single\n",
        "    2: 2,  # Married/Union\n",
        "    3: 3,  # Separated/Other\n",
        "    4: 3,  # Separated/Other\n",
        "    5: 2,  # Married/Union\n",
        "    6: 3   # Separated/Other\n",
        "}\n",
        "\n",
        "df['Marital status'] = df.apply(lambda row: map_categories(row, 'Marital status', marital_status_mapping), axis=1)```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imk_dBzvhbSU"
      },
      "source": [
        "Let's load the mapped dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adF0qSxGhbSU"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/xmqtgnRT0GpQnTsjJHDVTw/mapped-dropout-data.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU3IKez6hbSU"
      },
      "source": [
        "We need to drop the redundant column `Unnamed: 0` that was created while saving the mapped dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VACUO5mFhbSU"
      },
      "outputs": [],
      "source": [
        "data = data.drop('Unnamed: 0', axis = 1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxHHIRaShbSU"
      },
      "source": [
        "You can create graphs for each feature grouped by the target column. The distribution is influenced by various factors, including academic ones such as previous qualifications, as well as socio-economic challenges such as nationality, parental occupation, and tuition fees.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEViQdVchbSU"
      },
      "source": [
        "### <a id='data-visualization'></a>[Data visualization](#toc)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq7j-2ZehbSU"
      },
      "outputs": [],
      "source": [
        "# Get all the categorical columns and exlude the numeric ones\n",
        "cat_columns = data.columns.to_list()\n",
        "\n",
        "# List of numerical columns\n",
        "num_columns = ['Previous qualification (grade)', 'Admission grade',\n",
        "               'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)']\n",
        "\n",
        "# Remove the numerical columns from cat_columns\n",
        "for col in num_columns:\n",
        "    cat_columns.remove(col)\n",
        "\n",
        "cat_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU7o5OCrhbSV"
      },
      "outputs": [],
      "source": [
        "for column in cat_columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.countplot(x='Target', hue=column, data=data)\n",
        "    plt.title(f'Count of {column} by Target')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xlabel('Target')\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FLZVurbhbSV"
      },
      "source": [
        "Now, let's take a look at the numerical feature's graph for better understanding:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4B8wj1yhbSV"
      },
      "outputs": [],
      "source": [
        "for column in num_columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for target in data['Target'].unique():\n",
        "        subset = data[data['Target'] == target]\n",
        "        sns.histplot(subset[column], kde=True, label=target, element=\"step\", alpha=0.6)\n",
        "    plt.title(f'Distribution of {column} by Target')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Count')\n",
        "    plt.legend(title='Target')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAZ0rhmohbSV"
      },
      "source": [
        "### <a id='model-training'></a>[Model training](#toc)\n",
        "\n",
        "Assign the `Target` column to the variable y to store the labels for classification tasks, and split the data into training and testing sets for model training and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTiC_fXchbSV"
      },
      "outputs": [],
      "source": [
        "y = data['Target']\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J_SSNethbSV"
      },
      "source": [
        "Drop the 'Target' column from the DataFrame and assign the remaining features to X for use as input variables in the machine learning model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgrVgZgghbSV"
      },
      "outputs": [],
      "source": [
        "X = data.drop('Target',axis=1)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8EKt9wehbSW"
      },
      "source": [
        "Split the dataset into training and testing sets with 80% for training and 20% for testing, using a random seed for reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCdgXURMhbSW"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lRI6c8GhbSW"
      },
      "source": [
        "### <a id='training-decision-tree-classifier'></a>[Training decision tree classifier](#toc)  \n",
        "\n",
        "Train a `DecisionTreeClassifier` with default settings (skipping hyperparameter tuning via grid search), and evaluate the model using accuracy, confusion matrix, and classification report. Decision trees split the features using thresholds or categories directly without requiring numerical transformations, as they are able to work with non-numeric data efficiently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2hzqFwuhbSW"
      },
      "outputs": [],
      "source": [
        "def decisonTreeClassifier(X_train, y_train, X_test, y_test):\n",
        "    clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "    # Train the model on the training set\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    return y_pred, clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k17LGDcdhbSW"
      },
      "outputs": [],
      "source": [
        "y_pred, clf = decisonTreeClassifier(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFK6c4NVhbSW"
      },
      "outputs": [],
      "source": [
        " # Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\\n\")\n",
        "print(f\"Confusion Matrix: \\n{conf_matrix}\\n\")\n",
        "print(f\"Classification Report: \\n{class_report}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q54A-KlhbSW"
      },
      "source": [
        "The model achieved an overall **accuracy of 70%**. While the precision and recall for the **Graduate** class are high (precision: 0.84, recall: 0.79), performance for the **Enrolled** class is significantly lower, with a precision of **0.37** and recall of **0.42**, indicating that the model struggles to predict this class correctly. The **Dropout** class has balanced performance with a precision and recall around **0.70**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9g3v5GshbSW"
      },
      "source": [
        "Let's visualize the confusion matrix with class labels using `ConfusionMatrixDisplay` for visual evaluation of model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxyA12-whbSW"
      },
      "outputs": [],
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=clf.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIpWW-CahbSX"
      },
      "source": [
        "The confusion matrix shows that the model performs well in predicting the **Graduate** class, with **355 correct predictions out of 450**. For the **Dropout** class, **201 instances were correctly classified**, but **52 were misclassified as Enrolled** and **31 as Graduate**, indicating some overlap. The **Enrolled** class has the highest misclassification, with a large number of predictions being confused with both **Dropout** and **Graduate**, highlighting the model's difficulty in distinguishing this class from others.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_XJ6oa6hbSX"
      },
      "source": [
        "### <a id='feature-importance-in-decision-tree'></a>[Feature importance in decision tree](#toc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyWPeXx6hbSX"
      },
      "source": [
        "Feature importance scores indicate how important each feature is in making predictions. They represent how much splitting based on a particular feature reduces the classification error, entropy, or Gini index in decision trees or random forests. Essentially, the higher the feature importance score, the more that feature contributes to improving the model's performance. We can print out the feature names alongside their corresponding importance scores to better understand which features are driving the predictions. Feature importance also aids in interpretability of the machine learning model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b9HEQbfhbSX"
      },
      "outputs": [],
      "source": [
        "print(\"Feature name \", X_train.columns, \"\\n\")\n",
        "print(\"Feature importance \", clf.feature_importances_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bItaFQLHhbSX"
      },
      "source": [
        "The following function will plot the feature importance in a bar graph (the fuction `display_feature_importances` is defined in the Helper function section at the beginning of the notebook).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga7uIj-0hbSX"
      },
      "outputs": [],
      "source": [
        "feature_importance_trees = display_feature_importances(clf, X_train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMw9ZgvWhbSX"
      },
      "source": [
        "### <a id='insights-from-feature-importance-and-identifying-data-leakage'></a>[Insights from feature importance and identifying data leakage](#toc)    \n",
        "\n",
        "The feature **\"Curricular units 2nd sem (approved)\"** has the **highest importance** by a significant margin compared to all other features. This dominance is suspicious and raises concerns about potential **data leakage** in the model.\n",
        "\n",
        "#### Identifying data leakage\n",
        "Upon further inspection of the dataset:\n",
        "\n",
        "- **\"Curricular units 2nd sem (approved)\"** is highly correlated with the target variable (e.g., Dropout, Enrolled, Graduate).\n",
        "- Conceptually, this feature reflects an **outcome** rather than a predictive input because it depends on what happens **after** the event we are trying to predict.  \n",
        "  - For example, if a student drops out during the semester, they will not complete or pass any courses, resulting in **0 approved units**.  \n",
        "  - This is a **result of dropping out**, not something that causes it.\n",
        "\n",
        "Including such features in model training introduces **data leakage** because the model indirectly learns information about the target variable that would **not** be available at the time of prediction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icyblx3ChbSX"
      },
      "source": [
        "### <a id='training-random-forest-classifier'></a>[Training random forest classifier](#toc)  \n",
        "\n",
        "A Random Forest is an ensemble method that builds multiple decision trees and combines their predictions to improve accuracy and reduce overfitting. It is better than individual decision trees because it averages the results of many trees, leading to more robust and generalized predictions. Additionally, Random Forests can generate feature importance scores, showing which features contribute most to making decisions across the entire forest.\n",
        "\n",
        "The code for training and evaluating a Random Forest is almost identical to that for a Decision Tree. The key difference is that the Random Forest builds multiple decision trees and combines their predictions, while a single Decision Tree uses only one model. In the Random Forest, the number of trees (n_estimators) is an important hyperparameter that can be tuned to control the number of trees in the ensemble, typically leading to more stable and accurate predictions as the number increases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieA6wpQ-hbSX"
      },
      "outputs": [],
      "source": [
        "def randomForestClassifier(X_train, y_train, X_test, y_test):\n",
        "    random_forest_model = RandomForestClassifier(random_state=42,n_estimators=100)\n",
        "\n",
        "    # Train the model on the training set\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "    return y_pred, random_forest_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT4pqYwOhbSY"
      },
      "outputs": [],
      "source": [
        "y_pred, random_forest_model = randomForestClassifier(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5QFycRrhbSY"
      },
      "outputs": [],
      "source": [
        " # Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\\n\")\n",
        "print(f\"Confusion Matrix: \\n{conf_matrix}\\n\")\n",
        "print(f\"Classification Report: \\n{class_report}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-5dqhE9hbSY"
      },
      "source": [
        "The model achieved an overall **accuracy of 80%**, showing improved performance compared to previous results. The **Graduate** class continues to perform exceptionally well, with a precision of **0.83** and a high recall of **0.94**, indicating that the model correctly identifies most graduates. For the **Dropout** class, both precision and recall remain balanced at around **0.83** and **0.79**, respectively, highlighting reliable performance. However, the **Enrolled** class still struggles, with a lower precision of **0.61** and recall of **0.43**, suggesting the model has difficulty distinguishing this class from the others.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFCvJVUphbSY"
      },
      "source": [
        "Let's visualize the confusion matrix with class labels using `ConfusionMatrixDisplay` for visual evaluation of model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB-q7mi5hbSY"
      },
      "outputs": [],
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=random_forest_model.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Olce4BmhbSY"
      },
      "source": [
        "The confusion matrix shows that the model performs exceptionally well in predicting the **Graduate** class, with **423 correct predictions out of 450**. For the **Dropout** class, **224 instances were correctly classified**, but **25 were misclassified as Enrolled** and **35 as Graduate**, indicating some overlap with other classes. The **Enrolled** class exhibits the highest misclassification, with **35 instances misclassified as Dropout** and **51 as Graduate**, highlighting the model's difficulty in distinguishing this class from others.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHiHsXt0hbSY"
      },
      "source": [
        "On average, the decision tree performs well, particularly in terms of precision and recall for the **Dropout** predictions. Additionally, the **feature importance** provides insights into which features contribute the most to the model's predictions. In a decision tree, feature importance is calculated based on how much each feature reduces the impurity (e.g., Gini or entropy) across all splits in the tree. This information helps identify the most influential features that improve the model's accuracy and can guide further analysis or feature selection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bcp4_HbhbSY"
      },
      "source": [
        "### <a id='feature-importance-in-random-forest'></a>[Feature importance in random forest](#toc)  \n",
        "\n",
        "The following function will plot the feature importance in a bar graph (the fuction `display_feature_importances` is defined in the helper function section at the beginning of the notebook).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRVJDxy_hbSY"
      },
      "outputs": [],
      "source": [
        "feature_importance_rf = display_feature_importances(random_forest_model, X_train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCaEMEPYhbSY"
      },
      "source": [
        "## <a id='handling-data-leakage'></a>[Handling data leakage](#toc)\n",
        "\n",
        "We observed that **'Curricular units 2nd sem (approved)'** had the **highest feature importance** in our model. This raised a red flag, prompting us to investigate further for potential **data leakage**.\n",
        "\n",
        "#### How we identified data leakage\n",
        "\n",
        "1. **Conceptual analysis**:\n",
        "   - The feature **'Curricular units 2nd sem (approved)'** indicates the number of courses a student passed in the second semester.\n",
        "   - If a student drops out mid-semester, they would naturally have **0 approved units**. This means the feature is a **consequence of the target outcome** (Dropout, Enrolled, Graduate), not a predictor.\n",
        "\n",
        "2. **Correlation with target**:\n",
        "   - Upon checking, we found that the feature was highly correlated with the target variable.\n",
        "   - For example, **dropouts consistently had 0 approved units**, directly signaling the outcome.\n",
        "\n",
        "3. **Timing issue**:\n",
        "   - Since this information is only known **after the semester ends**, it would not be available at the time we are trying to make predictions (e.g., predicting dropout risk early in the semester).\n",
        "\n",
        "#### Addressing data leakage\n",
        "\n",
        "To ensure a fair and realistic model:\n",
        "\n",
        "1. We will **remove the column 'Curricular units 2nd sem (approved)'** from the dataset.\n",
        "2. We will retrain the **DecisionTreeClassifier** to evaluate its performance without this feature.\n",
        "\n",
        "By addressing data leakage, the model now uses only **valid predictors** available before the outcome occurs, ensuring it can generalize to unseen data more effectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkrDmjXfhbSZ"
      },
      "outputs": [],
      "source": [
        "data = data.drop('Curricular units 2nd sem (approved)', axis=1)\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nj2xbtehbSZ"
      },
      "outputs": [],
      "source": [
        "# After dropping the column we begin the model training\n",
        "y = data['Target']\n",
        "y.head()\n",
        "\n",
        "X = data.drop('Target',axis=1)\n",
        "X.head()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-60qkPMhbSZ"
      },
      "outputs": [],
      "source": [
        "y_pred, clf = decisonTreeClassifier(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt04zOKAhbSZ"
      },
      "outputs": [],
      "source": [
        " # Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\\n\")\n",
        "print(f\"Confusion Matrix: \\n{conf_matrix}\\n\")\n",
        "print(f\"Classification Report: \\n{class_report}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUkzCQabhbSZ"
      },
      "outputs": [],
      "source": [
        "feature_importance_trees = display_feature_importances(clf, X_train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJnCWBdohbSZ"
      },
      "source": [
        "### <a id='insights-from-feature-importance-after-data-leakage'></a>[Insights from feature importance after data leakage](#toc)  \n",
        "\n",
        "1. **Top features**:\n",
        "   - The feature **\"Curricular units 1st sem (approved)\"** has the highest importance, followed by **\"Curricular units 2nd sem (grade)\"** and **\"Tuition fees up to date\"**.\n",
        "   - These features dominate the predictions, suggesting they are strong signals for predicting student outcomes.\n",
        "\n",
        "2. **Potential data leakage**:\n",
        "   - Similar to the earlier case with **\"Curricular units 2nd sem (approved)\"**, the feature **\"Curricular units 1st sem (approved)\"** also needs to be carefully analyzed for **data leakage**.\n",
        "     - Conceptually, the number of approved courses in the first semester may reflect information that becomes available **after the semester ends**.\n",
        "     - If students drop out mid-semester, they may have **0 approved courses**, making this feature a consequence of dropping out rather than a cause.\n",
        "\n",
        "3. **Suspicion of timing issues**:\n",
        "   - Features such as **\"Curricular units 2nd sem (grade)\"** and **\"Curricular units 2nd sem (evaluations)\"** may also have timing-related issues, as they indicate outcomes or progress after the semester concludes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k6rZmJwhbSZ"
      },
      "source": [
        "### <a id='addressing-additional-data-leakage'></a>[Addressing additional data leakage](#toc)  \n",
        "\n",
        "After careful consideration and a detailed review of the dataset, it has been observed that several features may introduce **data leakage** into the model. These features reflect outcomes or progress that occur **after the event we are trying to predict** (e.g., dropout, enrolled, graduate). Using such features violates the principle of predictive modeling, as this information would not be available at the time of prediction.\n",
        "\n",
        "The following features were identified to contain data leakage:\n",
        "\n",
        "- **'Curricular units 1st sem (approved)'**\n",
        "- **'Curricular units 2nd sem (grade)'**\n",
        "- **'Curricular units 1st sem (grade)'**\n",
        "- **'Curricular units 2nd sem (evaluations)'**\n",
        "- **'Curricular units 1st sem (enrolled)'**\n",
        "- **'Curricular units 2nd sem (enrolled)'**\n",
        "- **'Curricular units 1st sem (credited)'**\n",
        "- **'Curricular units 1st sem (evaluations)'**\n",
        "- **'Curricular units 1st sem (without evaluations)'**\n",
        "- **'Curricular units 2nd sem (credited)'**\n",
        "- **'Curricular units 2nd sem (without evaluations)'**\n",
        "\n",
        "These columns either represent approved units, grades, or evaluations, which are **results** of the academic process rather than inputs available at the start. To mitigate data leakage, we will remove these columns from the dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bKoYjKvhbSZ"
      },
      "outputs": [],
      "source": [
        "data = data.drop(['Curricular units 1st sem (approved)', 'Curricular units 2nd sem (grade)', 'Curricular units 1st sem (grade)', 'Tuition fees up to date', 'Curricular units 2nd sem (evaluations)', 'Curricular units 1st sem (enrolled)', 'Curricular units 2nd sem (enrolled)', 'Curricular units 1st sem (credited)',\n",
        "       'Curricular units 1st sem (evaluations)',\n",
        "       'Curricular units 1st sem (without evaluations)',\n",
        "       'Curricular units 2nd sem (credited)',\n",
        "       'Curricular units 2nd sem (without evaluations)'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d3LViRxhbSZ"
      },
      "outputs": [],
      "source": [
        "# After dropping the column we begin the model training\n",
        "y = data['Target']\n",
        "y.head()\n",
        "\n",
        "X = data.drop('Target',axis=1)\n",
        "X.head()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4mf9AbKhbSZ"
      },
      "outputs": [],
      "source": [
        "y_pred, clf = decisonTreeClassifier(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAQlzkk4hbSa"
      },
      "outputs": [],
      "source": [
        " # Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\\n\")\n",
        "print(f\"Confusion Matrix: \\n{conf_matrix}\\n\")\n",
        "print(f\"Classification Report: \\n{class_report}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wp-8OoWhbSa"
      },
      "outputs": [],
      "source": [
        "feature_importance_trees = display_feature_importances(clf, X_train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bytXnbPEhbSa"
      },
      "source": [
        "### <a id='insights-from-feature-importance-after-additional-data-leakage'></a>[Insights from feature importance after additional data leakage](#toc)  \n",
        "\n",
        "After addressing **data leakage** by removing outcome-based features such as **'Curricular units 1st sem (approved)'** and others, we now see a more balanced and realistic distribution of feature importance.\n",
        "\n",
        "1. **Top features**:\n",
        "   - **\"Admission grade\"** and **\"Previous qualification (grade)\"** are now the most important features, which makes sense as they represent **prior academic performance** available at the time of enrollment.\n",
        "   - **\"Age at enrollment\"**, **\"Mother's occupation\"**, and **\"Father's occupation\"** are also key predictors, reflecting demographic and socio-economic factors that can influence a students success.\n",
        "\n",
        "2. **Removal of outcome-based features**:\n",
        "   - By eliminating features that directly reflect academic results (e.g., approved courses, evaluations, grades during semesters), we have mitigated **data leakage**.\n",
        "   - The model now uses features that are available **before or at the time of prediction**, ensuring fairness and generalizability.\n",
        "\n",
        "3. **Balanced contributions**:\n",
        "   - Features like **\"Scholarship holder\"**, **\"Unemployment rate\"**, and **\"Course\"** provide meaningful contributions, indicating that multiple factors influence the prediction.\n",
        "\n",
        "Before handling **data leakage**, the decision tree model achieved higher accuracy, but this performance was misleading as it relied on **outcome-based features** that would not be available at prediction time. While accuracy dropped after removing these features, the updated model now reflects a **realistic and fair evaluation**, using only valid predictors available **before the event occurs**. Addressing data leakage is crucial to ensure the model is robust, generalizable, and trustworthy for real-world applications.\n",
        "\n",
        "#### Conclusion:\n",
        "The updated model now relies on valid predictors without data leakage. The feature importance graph shows a logical hierarchy of factors, such as prior academic performance, socio-economic conditions, and demographic attributes. This ensures the model's predictions are both interpretable and robust for real-world use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXlwpW6RhbSa"
      },
      "source": [
        "Now let's check how is the scenario by training `randomForestClassifier` with the updated dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZtzZM3dhbSa"
      },
      "outputs": [],
      "source": [
        "y_pred, random_forest_model = randomForestClassifier(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6Of1hw4hbSa"
      },
      "outputs": [],
      "source": [
        " # Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\\n\")\n",
        "print(f\"Confusion Matrix: \\n{conf_matrix}\\n\")\n",
        "print(f\"Classification Report: \\n{class_report}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9bc-SrihbSa"
      },
      "source": [
        "### <a id='comparison-between-decision-tree-and-random-forest-models'></a>[Comparison between decision tree and random forest models](#toc)\n",
        "\n",
        "| **Metric**               | **Decision tree**       | **Random forest**        | **Observation**                       |\n",
        "|--------------------------|-------------------------|--------------------------|---------------------------------------|\n",
        "| **Accuracy**             | 50.4%                  | 62.0%                   | The **Random forest** model achieves a higher accuracy, compared to **Decision tree**, highlighting the benefit of using an ensemble method. |\n",
        "| **Dropout class (F1-Score)** | 0.50                  | 0.60                    | Random Forest performs better, with a higher F1-Score versus the Decision Tree. This indicates better classification for this class. |\n",
        "| **Enrolled class (F1-Score)** | 0.24                  | 0.19                    | Both models struggle significantly with the **Enrolled** class. The Decision Tree has slightly higher recall, but overall performance remains poor, suggesting the need for further improvements such as resampling or feature engineering. |\n",
        "| **Graduate class (F1-Score)** | 0.60                  | 0.73                    | Random Forest excels in predicting the **Graduate** class, achieving a better F1-Score compared to Decision Tree. This highlights its strength in handling majority classes. |\n",
        "\n",
        "### Conclusion:\n",
        "The **random forest** model outperforms the **decision tree** in overall accuracy and most individual class performances, particularly for **Dropout** and **Graduate** classes. However, both models face challenges with the **Enrolled** class, indicating a need for further refinement, such as addressing class imbalance or feature enhancement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wobFwLr8hbSa"
      },
      "source": [
        "However, despite these advantages, random forests are not as interpretable as single decision trees. Since they combine the results of many trees, understanding the specific decision-making process for a given prediction becomes complex and difficult to visualize. This makes them less ideal for scenarios where model transparency is important.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLk3Rks_hbSa"
      },
      "source": [
        "### <a id='tree-visualization'></a>[Tree visualization](#toc)\n",
        "\n",
        "The **decision Tree visualization** provides a clear and interpretable representation of the models decision-making process. By setting **`max_depth=2`**, we limit the tree's depth to focus on the **top-level splits**, showing the most influential features and their thresholds. The **`filled=True`** and **`rounded=True`** options enhance readability, allowing us to easily distinguish between classes and understand how features are used to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmohm5ZphbSa"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))  # Adjust the size for better readability\n",
        "plot_tree(clf, feature_names=X_test.columns, class_names=clf.classes_,max_depth=2, filled=True, rounded=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFkPJclchbSb"
      },
      "source": [
        "### <a id='decision-tree-insights'></a>[Tree insights](#toc)\n",
        "\n",
        "1. **Root node**:  \n",
        "   - The tree starts with **\"Scholarship holder <= 0.5\"** as the primary split, dividing students based on whether they hold a scholarship.\n",
        "\n",
        "2. **Left branch (No scholarship)**:  \n",
        "   - Key splits include **\"Age at enrollment <= 22.5\"** and **\"Debtor <= 0.5\"**, leading to classifications such as **Dropout** and **Graduate**.\n",
        "\n",
        "3. **Right branch (With Scholarship)**:  \n",
        "   - Further splits on **\"Unemployment rate <= 8.25\"** and **Debtor status** predict **Graduate** outcomes with lower impurity.\n",
        "\n",
        "4. **Leaf nodes**:  \n",
        "   - Final outcomes (e.g., **Dropout** or **Graduate**) are determined based on these features, with **Gini index** values indicating the confidence of each classification.\n",
        "\n",
        "The tree identifies **Scholarship holder**, **Age at enrollment**, and **Unemployment rate** as the most influential features for predicting student outcomes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiMH6GMDhbSb"
      },
      "source": [
        "You can visualize the tree rules with proper readability:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpEPMmCjhbSb"
      },
      "outputs": [],
      "source": [
        "tree_rules = export_text(clf, feature_names=list(X_train.columns),max_depth=2)\n",
        "print(tree_rules)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_5oaP_fhbSb"
      },
      "source": [
        "### <a id='tree-visualization-using-treesplainer'></a>[Tree visualization using TreeSplainer](#toc)  \n",
        "\n",
        "The `TreeSplanerClassifier` class takes a trained **decision tree** and provides human-readable insights by:\n",
        "\n",
        "- Extracting decision rules in text format.  \n",
        "- Generating predictions with explanations for specific samples.  \n",
        "- Displaying branch impurity information to analyze split quality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBnS9I08hbSb"
      },
      "source": [
        "We start with encoding the target `y`. We do this because `TreeSplanerClassifier` class explicitly works with numerical indices for the predicted classes.\n",
        "\n",
        "- You may be wondering why are we encoding the target here but not earlier when we trained the decision tree and random forest?\n",
        "    * The reason for this is because these classifiers in Scikit-learn can handle categorical target variables (e.g., \"Dropout\", \"Enrolled\", \"Graduate\") directly by mapping these classes to numerical labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WX_MMQdhbSb"
      },
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = data.drop('Target', axis=1)\n",
        "y = data['Target']\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUBuFSuphbSb"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=0)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxtsi-A3hbSb"
      },
      "source": [
        "After training the decision tree classifier, let's start by initializing `TreeSplanerClassifier` object. Once initialized, the `tree_explainer.decision_tree_to_text()` function is used to extract the decision rules of the tree in **natural language format**. This function:\n",
        "\n",
        "- Traverses each branch of the decision tree to identify conditions (e.g., \"Feature X <= Y\").\n",
        "- Compiles these conditions into human-readable rules for every possible path in the tree.\n",
        "- Outputs the rules as text, including the predicted class and its probability at the leaf nodes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qk0MPBSchbSb"
      },
      "outputs": [],
      "source": [
        "# Initialize the TreeSplanerClassifier\n",
        "tree_explainer = TreeSplanerClassifier(\n",
        "    clf,\n",
        "    feature_names=X.columns.tolist(),\n",
        "    target_names=['Dropout', 'Enrolled', 'Graduate']\n",
        ")\n",
        "\n",
        "# Extract decision tree rules in text format\n",
        "decision_rules = tree_explainer.decision_tree_to_text()\n",
        "decision_rules[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzf9tzqnhbSb"
      },
      "source": [
        "Next, we generate text explanations for predictions. The `tree_explainer.build_text_prediction()` function is used to provide **text-based explanations** for predictions made by the decision tree model. Here,\n",
        "\n",
        "- **Input**: A subset of test samples (`X_test[:1].values`) is passed to the function.\n",
        "- **Process**:\n",
        "  - The function traverses the decision tree's path for each sample.\n",
        "  - It generates a sequence of rules (e.g., \"Feature X <= Y\") that the sample satisfies as it moves through the tree.\n",
        "  - The final prediction and its probability are appended at the end of the rule sequence.\n",
        "- **Output**: A human-readable explanation of how the model arrived at the prediction, including all the conditions leading to the predicted class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auBMxsIkhbSb"
      },
      "outputs": [],
      "source": [
        "# Generate predictions for some test samples and explain in text format\n",
        "test_sample_predictions = tree_explainer.build_text_prediction(X_test[:1].values)\n",
        "test_sample_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEL5IqJuhbSc"
      },
      "source": [
        "Here, we extract the branch impurity information. Branch impurity provides insight into how well a decision tree split separates the data at each node. It is measured using metrics like **Gini impurity** or **entropy**, which indicate the degree of \"mixed-ness\" of classes at a specific split:\n",
        "\n",
        "- **High impurity**: Indicates a mix of different classes, meaning the split does not separate them well.\n",
        "- **Low impurity**: Indicates that the split has successfully grouped data points of similar classes, reducing uncertainty.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSEn9_HYhbSc"
      },
      "source": [
        "The `tree_explainer.branch_impurity()` function is used to retrieve the impurity levels at each split of the decision tree for all branches.\n",
        "\n",
        "In this code:\n",
        "\n",
        "- **Purpose**: To analyze the **Gini impurity** at different splits in the tree, providing insights into how well each split separates the data.\n",
        "- **Output**:\n",
        "  - For each branch, the function lists:\n",
        "    - The split number.\n",
        "    - The feature used for the split.\n",
        "    - The impurity value (e.g., Gini index) at that split.\n",
        "  - Lower impurity values indicate better separation of classes at that node.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1iMBNYghbSc"
      },
      "outputs": [],
      "source": [
        "# Extract branch impurity information\n",
        "branch_impurities = tree_explainer.branch_impurity()\n",
        "branch_impurities[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdmVhn15hbSc"
      },
      "source": [
        "You can visualize the whole tree using `plot_tree` function. It may not be readable mainly because we are working with a huge dataset so there are many splitting criterion that comes into play.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSOa8exqhbSc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 10))  # Adjust figure size for better readability\n",
        "plot_tree(\n",
        "    clf,\n",
        "    feature_names=X.columns.tolist(),  # Feature names for nodes\n",
        "    class_names=['Dropout', 'Enrolled', 'Graduate'],  # Target class names\n",
        "    filled=True,  # Color nodes based on class or feature importance\n",
        "    rounded=True  # Round node boxes for aesthetics\n",
        ")\n",
        "plt.title(\"Decision Tree Visualization\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzwwu6WzhbSc"
      },
      "source": [
        "The rules that we have generated from the class can be stored in a dataframe for better readability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lS_m2-jhbSc"
      },
      "outputs": [],
      "source": [
        "# Extract all paths from the TreeSplanerClassifier\n",
        "all_paths = tree_explainer.find_paths_from_root()\n",
        "\n",
        "# Prepare data for tabular visualization\n",
        "rules_data = []\n",
        "for path in all_paths:\n",
        "    conditions = []\n",
        "    for node in path[:-1]:  # Exclude the leaf node\n",
        "        if node in tree_explainer.children_right:\n",
        "            eq = \">\"\n",
        "        else:\n",
        "            eq = \"<=\"\n",
        "        condition = f\"{tree_explainer.feature_names[tree_explainer.feature[node]]} {eq} {round(tree_explainer.threshold[node], 2)}\"\n",
        "        conditions.append(condition)\n",
        "\n",
        "    # Extract class and probability at the leaf node\n",
        "    leaf_node = path[-1]\n",
        "    predicted_class = tree_explainer.target_names[np.argmax(tree_explainer.value[leaf_node][0])]\n",
        "    probability = round(np.max(tree_explainer.value[leaf_node][0]) / np.sum(tree_explainer.value[leaf_node][0]), 3)\n",
        "\n",
        "    # Append to rules_data\n",
        "    rules_data.append({\n",
        "        \"Rule\": \" AND \".join(conditions),\n",
        "        \"Predicted Class\": predicted_class,\n",
        "        \"Probability\": probability\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "rules_df = pd.DataFrame(rules_data)\n",
        "rules_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49YCWxEmhbSc"
      },
      "outputs": [],
      "source": [
        "rules_df['Rule'].iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfwVlctohbSc"
      },
      "source": [
        "The output generated from the decision tree can be overwhelming and impractical to use in its raw form. The utility of this textual representation lies in specific use cases where interpretability and rule extraction are essential. Let's explain how this can be made useful:\n",
        "\n",
        "#### Potential use cases\n",
        "\n",
        "- **Interpretability for stakeholders:**\n",
        "    * In domains like education, healthcare, or finance, stakeholders may require insights into how predictions are made (e.g., why a student is classified as \"Dropout\"). By summarizing key rules instead of providing all paths, decision-makers can understand critical factors influencing the predictions.\n",
        "\n",
        "- **Feature importance analysis:**\n",
        "    * The extracted rules highlight which features and thresholds significantly impact decisions, helping identify the most important predictors.\n",
        "\n",
        "- **Rule-based system integration:**\n",
        "    * Rules can be directly integrated into systems where explicit decision-making criteria are required, such as automated workflows or audits.\n",
        "\n",
        "- **Debugging models:**\n",
        "    * Understanding decision paths can help debug issues with the model, such as overfitting or unexpected behavior.\n",
        "\n",
        "\n",
        "#### How to simplify this output\n",
        "\n",
        "- **Summarize key rules:**\n",
        "    * Extract only the most important paths (e.g., those contributing to a high proportion of predictions or those with a high probability).\n",
        "\n",
        "- **Visualize rules as a decision tree:**\n",
        "    * Use tools such as Graphviz to generate visual decision trees that are easier to interpret than raw text.\n",
        "\n",
        "- **Cluster and aggregate rules:**\n",
        "    * Group similar rules together to avoid redundancy and make the output concise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFGqlFymhbSc"
      },
      "outputs": [],
      "source": [
        "# Summarize key rules\n",
        "def summarize_rules(clf, feature_names):\n",
        "    rules = export_text(clf, feature_names=feature_names)\n",
        "    print(\"Decision Tree Rules Summary:\")\n",
        "    print(rules[:2000])  # Print the first 2000 characters for brevity\n",
        "    return rules\n",
        "\n",
        "# Example usage\n",
        "rules_summary = summarize_rules(clf, X.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd0Kbb3yhbSd"
      },
      "source": [
        "## <a id='exercises'></a>[Exercises](#toc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QJo_KD9hbSd"
      },
      "source": [
        "### <a id='Exercise-1'></a>[Exercise 1: Introduce data leakage in a decision tree classifier](#toc)\n",
        "**Task:** Add a \"leakage feature\" to the iris dataset (from sklearn.datasets import load_iris) that directly correlates with the target variable i.e. deliberately introduce a leakage feature to the Iris dataset to observe its impact on model training and performance. A leakage feature is a variable that is directly or indirectly correlated with the target variable, providing the model with information that would not be available at prediction time. Train a DecisionTreeClassifier, visualize the tree, and the feature importance plot. Identify the leakage feature.\n",
        "\n",
        "\n",
        "#### Question to yourself: Which feature shows unusually high importance? Why is this problematic?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENE8DNIKhbSd"
      },
      "source": [
        "### <a id='Exercise-2'></a>[Exercise 2: Compare models with and without data leakage](#toc)\n",
        "**Task:** Train two RandomForestClassifier models on the previously imported iris dataset, one with and one without the leakage feature. By comparing their performances and feature importances, you will observe how data leakage artificially inflates model accuracy and skews feature importance.\n",
        "\n",
        "#### Question to yourself: Why is the model with leakage misleading?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "prev_pub_hash": "7968e2a20e9c76e84836d34b3f9806b00f9c8fdbb4dbe51184f9194443184c80",
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
